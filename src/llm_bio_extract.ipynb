{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import  AutoModel, AutoTokenizer,AutoModelForCausalLM\n",
    "# model_name = 'lmsys/vicuna-33b-v1.3'\n",
    "# print(\"Loading model ...\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name) \n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", load_in_8bit=True)\n",
    "# model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s2220429/phuongnm-exp/SP_LLMs/env_llm/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n",
      "Loading checkpoint shards: 100%|██████████| 15/15 [00:21<00:00,  1.43s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import LlamaTokenizer, AutoModel, AutoTokenizer,LlamaForCausalLM\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TrainingArguments, AutoConfig\n",
    "\n",
    "print(\"Loading model ...\")\n",
    "model_name = 'meta-llama/Llama-2-70b-chat-hf'   # trained with chat and instruction  \n",
    "# model_name = 'meta-llama/Meta-Llama-3-8B-Instruct'  #  standard model \n",
    "tensor_data_type = torch.bfloat16  \n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=tensor_data_type\n",
    ")\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    # return_dict=True,\n",
    "    load_in_8bit=True,\n",
    "    device_map=\"auto\",\n",
    "    # low_cpu_mem_usage=True,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"../\")\n",
    "from main import BatchPreprocessor\n",
    "import json\n",
    "\n",
    "class BatchPreprocessorLLM(BatchPreprocessor): \n",
    "    def __init__(self, tokenizer, dataset_name=None, window_ct=2, emotion_labels=[]) -> None:\n",
    "        self.tokenizer = tokenizer\n",
    "        self.separate_token_id = self.tokenizer.convert_tokens_to_ids(\"</s>\")\n",
    "        self.dataset_name  = dataset_name\n",
    "        self.window_ct = window_ct\n",
    "        self.emotion_labels = emotion_labels\n",
    "        self.printted = False\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_raw_data(path_data):\n",
    "        raw_data = json.load(open(path_data))\n",
    "        if isinstance(raw_data, dict):\n",
    "            new_data_list = []\n",
    "            for k, v in raw_data.items():\n",
    "                v['s_id'] = k\n",
    "                new_data_list.append(v)\n",
    "            return new_data_list\n",
    "        elif isinstance(raw_data, list):\n",
    "            return raw_data\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_speaker_name(s_id, gender, data_name):\n",
    "        if data_name == \"iemocap\":\n",
    "            # iemocap: label index mapping = {'hap':0, 'sad':1, 'neu':2, 'ang':3, 'exc':4, 'fru':5}\n",
    "            speaker = {\n",
    "                        \"Ses01\": {\"F\": \"Mary\", \"M\": \"James\"},\n",
    "                        \"Ses02\": {\"F\": \"Patricia\", \"M\": \"John\"},\n",
    "                        \"Ses03\": {\"F\": \"Jennifer\", \"M\": \"Robert\"},\n",
    "                        \"Ses04\": {\"F\": \"Linda\", \"M\": \"Michael\"},\n",
    "                        \"Ses05\": {\"F\": \"Elizabeth\", \"M\": \"William\"},\n",
    "                    }\n",
    "            s_id_first_part = s_id[:5]\n",
    "            return speaker[s_id_first_part][gender].upper()\n",
    "        elif data_name in ['meld', \"emorynlp\"]:\n",
    "            # emorynlp: label index mapping =  {'Joyful': 0, 'Mad': 1, 'Peaceful': 2, 'Neutral': 3, 'Sad': 4, 'Powerful': 5, 'Scared': 6}\n",
    "            # meld: label index mapping = {'neutral': 0, 'surprise': 1, 'fear': 2, 'sadness': 3, 'joy': 4, 'disgust': 5, 'anger':6}\n",
    "            gender_idx = gender.index(1) \n",
    "            return f\"SPEAKER_{gender_idx}\"\n",
    "        elif data_name=='dailydialog':\n",
    "            # dailydialog:  {'no_emotion': 0, 'happiness': 1, 'sadness': 2, 'surprise': 3,  'anger': 4, 'fear': 5, 'disgust':6}\n",
    "            return f\"SPEAKER_{gender}\"\n",
    "        \n",
    "    def sentence_mixed_by_surrounding(self, sentences, around_window, s_id, genders, data_name):\n",
    "        new_conversations = []\n",
    "        align_sents = []\n",
    "        for i, cur_sent in enumerate(sentences):\n",
    "            tmp_s = \"\"\n",
    "            for j in range(max(0, i-around_window), min(len(sentences), i+around_window+1)):\n",
    "                u_j =  f\"{self.get_speaker_name(s_id, genders[j], data_name=data_name)}: {sentences[j]}\"\n",
    "                if i == j:\n",
    "                    align_sents.append(u_j)\n",
    "                tmp_s +=  f\"\\n{u_j}\"\n",
    "            new_conversations.append(tmp_s)\n",
    "        return new_conversations, align_sents\n",
    "    \n",
    "    def __call__(self, batch):\n",
    "        raw_sentences = []\n",
    "        raw_sentences_flatten = []\n",
    "        labels = []\n",
    "        speaker_info = []\n",
    "        listener_info = []\n",
    "\n",
    "        # masked tensor  \n",
    "        lengths = [len(sample['sentences']) for sample in batch]\n",
    "        max_len_conversation = max(lengths)\n",
    "        padding_utterance_masked = torch.BoolTensor([[False]*l_i+ [True]*(max_len_conversation - l_i) for l_i in lengths])\n",
    "\n",
    "        # collect all sentences\n",
    "        # - intra speaker\n",
    "        flatten_data = []\n",
    "        intra_speaker_masekd_all = torch.BoolTensor(len(batch), max_len_conversation,max_len_conversation)\n",
    "        for i, sample in enumerate(batch):\n",
    "            new_conversations, align_sents = self.sentence_mixed_by_surrounding(sample['sentences'], \n",
    "                                                                        around_window=self.window_ct, \n",
    "                                                                        s_id=sample['s_id'], \n",
    "                                                                        genders=sample['genders'],\n",
    "                                                                        data_name=self.dataset_name)\n",
    "            few_shot_example = \"\"\"\\n=======\n",
    "Context: Given predefined emotional label set [happy, sad, neutral, angry, excited, frustrated], and bellow conversation: \n",
    "\"\n",
    "PATRICIA: You know, it's lovely here, the air is sweet.\n",
    "PATRICIA: No, not sorry.  But, um. But I'm not gonna stay.\n",
    "JOHN: The trouble is, I planned on sort of sneaking up on you on a period of a week or so.  But they take it for granted that we're all set.\n",
    "PATRICIA: I knew they would, your mother anyway.\n",
    "PATRICIA: Well, from her point of view, why else would I come?\n",
    "PATRICIA: I guess this is why I came.\n",
    "JOHN: I'm embarrassing you and I didn't want to tell it to you here.  I wanted some place we'd never been before.  A place where we'd be brand new to each other.\n",
    "PATRICIA: Well, you started to write me\n",
    "JOHN: You felt something that far back?\n",
    "PATRICIA: Every day since.\n",
    "JOHN: Ann, why didn't you let me know?\n",
    "JOHN: Let's drive someplace.  I want to be alone with you.\n",
    "JOHN: No.  Nothing like that.\n",
    "\"\n",
    "\n",
    "Question: What is the emotion of the speaker at the utterance \"PATRICIA: Well, from her point of view, why else would I come?\"?\n",
    "Answer: neutral\n",
    "\n",
    "Question: What is the emotion of the speaker at the utterance \"PATRICIA: I guess this is why I came.\"?\n",
    "Answer: happy\n",
    "\n",
    "Question: What is the emotion of the speaker at the utterance \"JOHN: I'm embarrassing you and I didn't want to tell it to you here.  I wanted some place we'd never been before.  A place where we'd be brand new to each other.\"?\n",
    "Answer: excited\n",
    "\"\"\"\n",
    "            for i_u, (conv, utterance) in enumerate(zip(new_conversations, align_sents)):\n",
    "                prompt_extract_context_vect = few_shot_example + f\"\\n=======\\nContext: Given predefined emotional label set [{', '.join(self.emotion_labels)}], and bellow conversation:\\n\\\"{conv}\\n\\\"\\n\\nQuestion: What is the emotion of the speaker at the utterance \\\"{utterance}\\\"?\\nAnswer:\" \n",
    "                if not self.printted:\n",
    "                    print(prompt_extract_context_vect)\n",
    "                    self.printted = True \n",
    "                    \n",
    "                inputs = self.tokenizer(prompt_extract_context_vect, return_tensors=\"pt\")\n",
    "                input_ids = inputs[\"input_ids\"] \n",
    "                flatten_data.append({\n",
    "                    \"s_id\": sample['s_id'],\n",
    "                    \"u_idx\": i_u,\n",
    "                    \"prompt_content\": prompt_extract_context_vect,\n",
    "                    \"input_ids\": input_ids,\n",
    "                    }\n",
    "                )\n",
    "                \n",
    "        return flatten_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BatchPreprocessorLLMSpeakerDescription(BatchPreprocessor): \n",
    "    def __init__(self, tokenizer, dataset_name=None, window_ct=2, emotion_labels=[]) -> None:\n",
    "        self.tokenizer = tokenizer\n",
    "        self.separate_token_id = self.tokenizer.convert_tokens_to_ids(\"</s>\")\n",
    "        self.dataset_name  = dataset_name\n",
    "        self.window_ct = window_ct\n",
    "        self.emotion_labels = emotion_labels\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_raw_data(path_data):\n",
    "        raw_data = json.load(open(path_data))\n",
    "        if isinstance(raw_data, dict):\n",
    "            new_data_list = []\n",
    "            for k, v in raw_data.items():\n",
    "                v['s_id'] = k\n",
    "                new_data_list.append(v)\n",
    "            return new_data_list\n",
    "        elif isinstance(raw_data, list):\n",
    "            return raw_data\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_speaker_name(s_id, gender, data_name):\n",
    "        if data_name == \"iemocap\":\n",
    "            # iemocap: label index mapping = {'hap':0, 'sad':1, 'neu':2, 'ang':3, 'exc':4, 'fru':5}\n",
    "            speaker = {\n",
    "                        \"Ses01\": {\"F\": \"Mary\", \"M\": \"James\"},\n",
    "                        \"Ses02\": {\"F\": \"Patricia\", \"M\": \"John\"},\n",
    "                        \"Ses03\": {\"F\": \"Jennifer\", \"M\": \"Robert\"},\n",
    "                        \"Ses04\": {\"F\": \"Linda\", \"M\": \"Michael\"},\n",
    "                        \"Ses05\": {\"F\": \"Elizabeth\", \"M\": \"William\"},\n",
    "                    }\n",
    "            s_id_first_part = s_id[:5]\n",
    "            return speaker[s_id_first_part][gender].upper()\n",
    "        elif data_name in ['meld', \"emorynlp\"]:\n",
    "            # emorynlp: label index mapping =  {'Joyful': 0, 'Mad': 1, 'Peaceful': 2, 'Neutral': 3, 'Sad': 4, 'Powerful': 5, 'Scared': 6}\n",
    "            # meld: label index mapping = {'neutral': 0, 'surprise': 1, 'fear': 2, 'sadness': 3, 'joy': 4, 'disgust': 5, 'anger':6}\n",
    "            gender_idx = gender.index(1) \n",
    "            return f\"SPEAKER_{gender_idx}\"\n",
    "        elif data_name=='dailydialog':\n",
    "            # dailydialog:  {'no_emotion': 0, 'happiness': 1, 'sadness': 2, 'surprise': 3,  'anger': 4, 'fear': 5, 'disgust':6}\n",
    "            return f\"SPEAKER_{gender}\"\n",
    "        \n",
    "    def preprocess(self, all_conversations):\n",
    "        \n",
    "        new_data = {}\n",
    "        gr_by_len = {}\n",
    "        for i, sample in enumerate(all_conversations):\n",
    "\n",
    "            all_utterances = []\n",
    "            all_speaker_names= []\n",
    "            for i_u, u in enumerate(sample['sentences']):\n",
    "                speaker_name = self.get_speaker_name(sample['s_id'], sample['genders'][i_u], self.dataset_name)\n",
    "                u_full_name = f'{speaker_name}: {u}'\n",
    "                all_utterances.append(u_full_name)\n",
    "                all_speaker_names.append(speaker_name) \n",
    "            \n",
    "            full_conversation = \"\\n\".join(all_utterances)\n",
    "            prompts_speaker_description_word_ids = {}\n",
    "            prompting_input = {}\n",
    "            for speaker_name in set(all_speaker_names):\n",
    "                prompting =\"\\nGiven this conversation between speakers: \\n\\\"\\n\" + full_conversation + \"\\n\\\"\\nIn overall of above conversation, what is speaker {}'s emotional transformations and personality traits? (Note: provide an answer within 250 words)\\nAnswer: \".format(speaker_name) \n",
    "\n",
    "                prompts_speaker_description_word_ids[speaker_name] = self.tokenizer(prompting, return_tensors=\"pt\")[\"input_ids\"]\n",
    "                prompting_input[speaker_name] = prompting\n",
    "                \n",
    "                # group by len for batch decode by llm \n",
    "                if prompts_speaker_description_word_ids[speaker_name].shape[-1] not in  gr_by_len:\n",
    "                    gr_by_len[prompts_speaker_description_word_ids[speaker_name].shape[-1]] = []\n",
    "                gr_by_len[prompts_speaker_description_word_ids[speaker_name].shape[-1]].append({\n",
    "                    'w_ids': prompts_speaker_description_word_ids[speaker_name],\n",
    "                    'conv_id': sample['s_id'],\n",
    "                    'type_data': sample['type_data'],\n",
    "                    \"prompting_input\": prompting,\n",
    "                    'speaker_name': speaker_name,\n",
    "                    'all_speaker_names': all_speaker_names\n",
    "                })\n",
    "                \n",
    "        return gr_by_len\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Continue process 114 conversations in data-type =valid\n",
      "- Continue process 280 conversations in data-type =test\n",
      "- Continue process 1038 conversations in data-type =train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/441 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\nGiven this conversation between speakers: \\n\"\\nSPEAKER_0: Oh my God, he\\x92s lost it. He\\x92s totally lost it.\\nSPEAKER_1: What?\\n\"\\nIn overall of above conversation, what is speaker SPEAKER_0\\'s emotional transformations and personality traits? (Note: provide an answer within 250 words)\\nAnswer: \\nSPEAKER_0\\'s emotional transformation throughout the conversation is one of increasing frustration and exasperation. Initially, they seem surprised and taken aback by the fact that the person they are talking about has \"lost it,\" but as the conversation progresses, their language becomes more emphatic and urgent, suggesting a growing sense of alarm and concern. They use phrases like \"oh my God\" and \"he\\'s totally lost it,\" which convey a sense of disbelief and worry. \\nIn terms of personality traits, SPEAKER_0 appears to be someone who is passionate and expressive, prone to dramatic language and strong emotions. They also seem to be someone who is invested in the well-being of the person they are talking about, as evidenced by their concern and alarm at the person\\'s behavior. Additionally, SPEAKER_0 seems to be someone who values clarity and directness in communication, as they ask for clarification and repeat back what they heard to ensure they understand the situation correctly. Overall, SPEAKER_0 comes across as a caring and emotionally expressive person who is invested in the conversation and the well-being of the people involved.', '\\nGiven this conversation between speakers: \\n\"\\nSPEAKER_0: Oh my God, he\\x92s lost it. He\\x92s totally lost it.\\nSPEAKER_1: What?\\n\"\\nIn overall of above conversation, what is speaker SPEAKER_1\\'s emotional transformations and personality traits? (Note: provide an answer within 250 words)\\nAnswer: \\nSPEAKER_1\\'s emotional transformations and personality traits can be inferred from their response to SPEAKER_0\\'s statement. Initially, SPEAKER_1 seems to be unaware of the situation and asks for clarification, indicating a lack of knowledge or understanding. This suggests that SPEAKER_1 may be curious and open-minded, willing to learn and gather information. \\nHowever, as the conversation progresses, SPEAKER_1 does not display any emotional reaction to SPEAKER_0\\'s statement, neither expressing concern nor surprise. This might indicate that SPEAKER_1 is stoic or unemotional, not easily affected by dramatic or unexpected events. \\nFurthermore, SPEAKER_1\\'s response is brief and straightforward, without any additional questions or comments. This could suggest that SPEAKER_1 is direct and to the point, valuing efficiency in communication. \\nOverall, SPEAKER_1\\'s personality traits and emotional transformations in this conversation suggest a practical, stoic, and curious individual.', '\\nGiven this conversation between speakers: \\n\"\\nSPEAKER_0: First of all, it\\'s on your ass.\\nSPEAKER_1: Well then, what is it?!\\n\"\\nIn overall of above conversation, what is speaker SPEAKER_0\\'s emotional transformations and personality traits? (Note: provide an answer within 250 words)\\nAnswer: \\nSPEAKER_0\\'s emotional transformations and personality traits can be inferred from their statement and the context of the conversation. At the beginning of the conversation, SPEAKER_0 seems to be in a playful and teasing mood, using a colloquialism (\"it\\'s on your ass\") to grab SPEAKER_1\\'s attention and create a lighthearted atmosphere. This suggests that SPEAKER_0 may be an outgoing and sociable person who enjoys engaging with others in a casual and friendly way. \\nHowever, when SPEAKER_1 responds with confusion and frustration, SPEAKER_0 does not offer any clarification or apology. Instead, they simply repeat their statement, which could be interpreted as a sign of stubbornness or a lack of empathy. This might indicate that SPEAKER_0 has a strong sense of self and is not easily swayed by others\\' opinions or emotions. \\nOverall, SPEAKER_0\\'s emotional transformations and personality traits in this conversation suggest that they are a confident and assertive individual who enjoys socializing but may struggle with empathy and flexibility in their interactions with others.\\n\\n\\n\\n\\n\\n', '\\nGiven this conversation between speakers: \\n\"\\nSPEAKER_0: First of all, it\\'s on your ass.\\nSPEAKER_1: Well then, what is it?!\\n\"\\nIn overall of above conversation, what is speaker SPEAKER_1\\'s emotional transformations and personality traits? (Note: provide an answer within 250 words)\\nAnswer: \\nSpeaker SPEAKER_1\\'s emotional transformations and personality traits can be inferred from their response to SPEAKER_0\\'s statement. At the beginning of the conversation, SPEAKER_1 seems to be confused and unsure about what SPEAKER_0 is referring to, as evidenced by their question, \"Well then, what is it?!\" This suggests that SPEAKER_1 may be a detail-oriented person who values clarity and precision in communication. \\nAs the conversation progresses, SPEAKER_1 becomes increasingly frustrated and defensive, as indicated by their use of exclamation marks and capital letters. This suggests that SPEAKER_1 may be a sensitive person who takes criticism or perceived criticism personally. \\nFurthermore, SPEAKER_1\\'s response of \"It\\'s on your ass\" implies that they may have a sarcastic or playful sense of humor, as they are using a figurative language to express their frustration. \\nOverall, SPEAKER_1 appears to be a detail-oriented person who values clarity, is sensitive to criticism, and has a playful sense of humor.', '\\nGiven this conversation between speakers: \\n\"\\nSPEAKER_0: Dude, you have got to turn on\\nSPEAKER_1: Let\\x92s go watch it at your place.\\n\"\\nIn overall of above conversation, what is speaker SPEAKER_0\\'s emotional transformations and personality traits? (Note: provide an answer within 250 words)\\nAnswer: \\nSPEAKER_0\\'s emotional transformations and personality traits can be inferred from the conversation as follows: \\nAt the beginning of the conversation, SPEAKER_0 seems excited and enthusiastic about something, possibly a TV show or movie. The use of the word \"dude\" and the exclamation \"you have got to turn on\" suggests that SPEAKER_0 is eager to share this experience with SPEAKER_1. \\nWhen SPEAKER_1 suggests watching it at SPEAKER_0\\'s place, SPEAKER_0 agrees, indicating that they are comfortable with the suggestion and open to spending time with SPEAKER_1. \\nOverall, SPEAKER_0 appears to be friendly, outgoing, and enthusiastic. They seem to enjoy sharing experiences with others and are open to socializing. Their use of colloquial language, such as \"dude,\" also suggests that they are relaxed and informal in their communication style. \\nHowever, it\\'s worth noting that this conversation is quite short, and it\\'s difficult to make a definitive judgment of SPEAKER_0\\'s personality traits based on this limited interaction.', '\\nGiven this conversation between speakers: \\n\"\\nSPEAKER_0: Dude, you have got to turn on\\nSPEAKER_1: Let\\x92s go watch it at your place.\\n\"\\nIn overall of above conversation, what is speaker SPEAKER_1\\'s emotional transformations and personality traits? (Note: provide an answer within 250 words)\\nAnswer: \\nFrom the conversation, it is clear that SPEAKER_1 is enthusiastic and eager to watch something. The speaker uses colloquial language such as \\x93dude\\x94 and \\x93let\\x92s go\\x94, which suggests a casual and friendly demeanor. Additionally, the speaker is willing to go to SPEAKER_0\\'s place to watch whatever it is that they want to watch, indicating that they are social and enjoy spending time with others. Overall, SPEAKER_1 appears to be an outgoing and laid-back individual. \\n\\nHowever, it is also possible that SPEAKER_1 is not necessarily enthusiastic about the activity itself, but rather the opportunity to socialize with SPEAKER_0. The speaker may be more interested in spending time with their friend than in the activity they are planning to do together. Alternatively, SPEAKER_1 may be genuinely excited about the activity, but their enthusiasm could also be a way of encouraging SPEAKER_0 to participate. Without more context, it is difficult to say for certain what SPEAKER_1\\'s emotional state and personality traits are.', '\\nGiven this conversation between speakers: \\n\"\\nSPEAKER_0: Hey! What are you guys doing?\\nSPEAKER_1: Making holiday candy for the neighbors.\\n\"\\nIn overall of above conversation, what is speaker SPEAKER_0\\'s emotional transformations and personality traits? (Note: provide an answer within 250 words)\\nAnswer: \\nSPEAKER_0\\'s emotional transformation in the conversation is one of curiosity and interest. At the beginning of the conversation, they express surprise and curiosity about what the other person is doing, indicating that they are not aware of the activity. As the conversation progresses, they show interest in the activity and ask questions about it, such as \"Making holiday candy for the neighbors?\" This suggests that they are open-minded and willing to learn about new things. \\n\\nIn terms of personality traits, SPEAKER_0 appears to be friendly and sociable. They initiate the conversation with a casual greeting, indicating that they are comfortable approaching others and starting conversations. They also show interest in the other person\\'s activities and ask questions, which suggests that they are a good listener and enjoy engaging with others. Additionally, their use of the phrase \"Hey!\" suggests that they are informal and relaxed in their communication style. Overall, SPEAKER_0\\'s emotional transformations and personality traits suggest that they are a friendly and curious individual who enjoys engaging with others.', '\\nGiven this conversation between speakers: \\n\"\\nSPEAKER_0: Hey! What are you guys doing?\\nSPEAKER_1: Making holiday candy for the neighbors.\\n\"\\nIn overall of above conversation, what is speaker SPEAKER_1\\'s emotional transformations and personality traits? (Note: provide an answer within 250 words)\\nAnswer: \\nFrom the conversation, it is clear that SPEAKER_1 is a friendly and helpful person. They are engaged in a positive activity of making holiday candy for their neighbors, which suggests that they are kind and considerate towards others. The fact that they are making candy for their neighbors also indicates that they value their relationships with the people around them and are willing to go the extra mile to make them happy. \\nFurthermore, SPEAKER_1\\'s response to SPEAKER_0\\'s question is straightforward and informative, suggesting that they are a direct and honest person. They do not seem to have any hidden motives or agendas, and their answer is simple and to the point. \\nOverall, SPEAKER_1 comes across as a friendly, kind, and honest person who values their relationships with others and is willing to put in effort to make them happy.']\n",
      "['\\nSPEAKER_0\\'s emotional transformation throughout the conversation is one of increasing frustration and exasperation. Initially, they seem surprised and taken aback by the fact that the person they are talking about has \"lost it,\" but as the conversation progresses, their language becomes more emphatic and urgent, suggesting a growing sense of alarm and concern. They use phrases like \"oh my God\" and \"he\\'s totally lost it,\" which convey a sense of disbelief and worry. \\nIn terms of personality traits, SPEAKER_0 appears to be someone who is passionate and expressive, prone to dramatic language and strong emotions. They also seem to be someone who is invested in the well-being of the person they are talking about, as evidenced by their concern and alarm at the person\\'s behavior. Additionally, SPEAKER_0 seems to be someone who values clarity and directness in communication, as they ask for clarification and repeat back what they heard to ensure they understand the situation correctly. Overall, SPEAKER_0 comes across as a caring and emotionally expressive person who is invested in the conversation and the well-being of the people involved.', \"\\nSPEAKER_1's emotional transformations and personality traits can be inferred from their response to SPEAKER_0's statement. Initially, SPEAKER_1 seems to be unaware of the situation and asks for clarification, indicating a lack of knowledge or understanding. This suggests that SPEAKER_1 may be curious and open-minded, willing to learn and gather information. \\nHowever, as the conversation progresses, SPEAKER_1 does not display any emotional reaction to SPEAKER_0's statement, neither expressing concern nor surprise. This might indicate that SPEAKER_1 is stoic or unemotional, not easily affected by dramatic or unexpected events. \\nFurthermore, SPEAKER_1's response is brief and straightforward, without any additional questions or comments. This could suggest that SPEAKER_1 is direct and to the point, valuing efficiency in communication. \\nOverall, SPEAKER_1's personality traits and emotional transformations in this conversation suggest a practical, stoic, and curious individual.\", '\\nSPEAKER_0\\'s emotional transformations and personality traits can be inferred from their statement and the context of the conversation. At the beginning of the conversation, SPEAKER_0 seems to be in a playful and teasing mood, using a colloquialism (\"it\\'s on your ass\") to grab SPEAKER_1\\'s attention and create a lighthearted atmosphere. This suggests that SPEAKER_0 may be an outgoing and sociable person who enjoys engaging with others in a casual and friendly way. \\nHowever, when SPEAKER_1 responds with confusion and frustration, SPEAKER_0 does not offer any clarification or apology. Instead, they simply repeat their statement, which could be interpreted as a sign of stubbornness or a lack of empathy. This might indicate that SPEAKER_0 has a strong sense of self and is not easily swayed by others\\' opinions or emotions. \\nOverall, SPEAKER_0\\'s emotional transformations and personality traits in this conversation suggest that they are a confident and assertive individual who enjoys socializing but may struggle with empathy and flexibility in their interactions with others.\\n\\n\\n\\n\\n\\n', '\\nSpeaker SPEAKER_1\\'s emotional transformations and personality traits can be inferred from their response to SPEAKER_0\\'s statement. At the beginning of the conversation, SPEAKER_1 seems to be confused and unsure about what SPEAKER_0 is referring to, as evidenced by their question, \"Well then, what is it?!\" This suggests that SPEAKER_1 may be a detail-oriented person who values clarity and precision in communication. \\nAs the conversation progresses, SPEAKER_1 becomes increasingly frustrated and defensive, as indicated by their use of exclamation marks and capital letters. This suggests that SPEAKER_1 may be a sensitive person who takes criticism or perceived criticism personally. \\nFurthermore, SPEAKER_1\\'s response of \"It\\'s on your ass\" implies that they may have a sarcastic or playful sense of humor, as they are using a figurative language to express their frustration. \\nOverall, SPEAKER_1 appears to be a detail-oriented person who values clarity, is sensitive to criticism, and has a playful sense of humor.', '\\nSPEAKER_0\\'s emotional transformations and personality traits can be inferred from the conversation as follows: \\nAt the beginning of the conversation, SPEAKER_0 seems excited and enthusiastic about something, possibly a TV show or movie. The use of the word \"dude\" and the exclamation \"you have got to turn on\" suggests that SPEAKER_0 is eager to share this experience with SPEAKER_1. \\nWhen SPEAKER_1 suggests watching it at SPEAKER_0\\'s place, SPEAKER_0 agrees, indicating that they are comfortable with the suggestion and open to spending time with SPEAKER_1. \\nOverall, SPEAKER_0 appears to be friendly, outgoing, and enthusiastic. They seem to enjoy sharing experiences with others and are open to socializing. Their use of colloquial language, such as \"dude,\" also suggests that they are relaxed and informal in their communication style. \\nHowever, it\\'s worth noting that this conversation is quite short, and it\\'s difficult to make a definitive judgment of SPEAKER_0\\'s personality traits based on this limited interaction.', \"\\nFrom the conversation, it is clear that SPEAKER_1 is enthusiastic and eager to watch something. The speaker uses colloquial language such as \\x93dude\\x94 and \\x93let\\x92s go\\x94, which suggests a casual and friendly demeanor. Additionally, the speaker is willing to go to SPEAKER_0's place to watch whatever it is that they want to watch, indicating that they are social and enjoy spending time with others. Overall, SPEAKER_1 appears to be an outgoing and laid-back individual. \\n\\nHowever, it is also possible that SPEAKER_1 is not necessarily enthusiastic about the activity itself, but rather the opportunity to socialize with SPEAKER_0. The speaker may be more interested in spending time with their friend than in the activity they are planning to do together. Alternatively, SPEAKER_1 may be genuinely excited about the activity, but their enthusiasm could also be a way of encouraging SPEAKER_0 to participate. Without more context, it is difficult to say for certain what SPEAKER_1's emotional state and personality traits are.\", '\\nSPEAKER_0\\'s emotional transformation in the conversation is one of curiosity and interest. At the beginning of the conversation, they express surprise and curiosity about what the other person is doing, indicating that they are not aware of the activity. As the conversation progresses, they show interest in the activity and ask questions about it, such as \"Making holiday candy for the neighbors?\" This suggests that they are open-minded and willing to learn about new things. \\n\\nIn terms of personality traits, SPEAKER_0 appears to be friendly and sociable. They initiate the conversation with a casual greeting, indicating that they are comfortable approaching others and starting conversations. They also show interest in the other person\\'s activities and ask questions, which suggests that they are a good listener and enjoy engaging with others. Additionally, their use of the phrase \"Hey!\" suggests that they are informal and relaxed in their communication style. Overall, SPEAKER_0\\'s emotional transformations and personality traits suggest that they are a friendly and curious individual who enjoys engaging with others.', \"\\nFrom the conversation, it is clear that SPEAKER_1 is a friendly and helpful person. They are engaged in a positive activity of making holiday candy for their neighbors, which suggests that they are kind and considerate towards others. The fact that they are making candy for their neighbors also indicates that they value their relationships with the people around them and are willing to go the extra mile to make them happy. \\nFurthermore, SPEAKER_1's response to SPEAKER_0's question is straightforward and informative, suggesting that they are a direct and honest person. They do not seem to have any hidden motives or agendas, and their answer is simple and to the point. \\nOverall, SPEAKER_1 comes across as a friendly, kind, and honest person who values their relationships with others and is willing to put in effort to make them happy.\"]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import os \n",
    "import traceback\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset_name = 'iemocap'\n",
    "data_folder = '../../data/all_raw_data/'\n",
    "prompt_type = 'spdescTrans'\n",
    "\n",
    "raw_data = []\n",
    "for type_data in ['valid', 'test', 'train']:\n",
    "    data_name_pattern= f'{dataset_name}.{type_data}'\n",
    "    path_processed_data = f'{data_folder}/llm_vectors/{data_name_pattern}_{prompt_type}_{model_name.split(\"/\")[-1]}.json'\n",
    "    \n",
    "    org_raw_data = BatchPreprocessorLLMSpeakerDescription.load_raw_data(f\"{data_folder}/{data_name_pattern}.json\")\n",
    "    \n",
    "    if os.path.exists(path_processed_data):\n",
    "        processed_data = json.load(open(path_processed_data, 'rt'))\n",
    "        print(f'- sucessful processed {len(processed_data)}/{len(org_raw_data)} conversations in data-type ={type_data}')\n",
    "        json.dump(processed_data, open(path_processed_data+\"_backup.json\", 'wt'), indent=2)\n",
    "        org_raw_data = [e for e in org_raw_data if e['s_id'] not in processed_data]\n",
    "        \n",
    "    print(f'- Continue process {len(org_raw_data)} conversations in data-type ={type_data}')\n",
    "    for e in org_raw_data:\n",
    "        e['type_data'] = type_data\n",
    "    raw_data = raw_data + org_raw_data\n",
    "    \n",
    "data_preprocessor = BatchPreprocessorLLMSpeakerDescription(tokenizer, dataset_name=dataset_name, window_ct=4, \n",
    "                                            emotion_labels=['happy', 'sad', 'neutral', 'angry', 'excited', 'frustrated'])\n",
    "\n",
    "gr_by_len  = data_preprocessor.preprocess(raw_data)\n",
    "all_data = {}\n",
    "print_one_time = True  \n",
    "for len_promting, speaker_promts in tqdm(gr_by_len.items()):\n",
    "    for batch_size in [8, 5, 2, 1]:\n",
    "        try:\n",
    "            all_promtings_texts = [e['prompting_input'] for e in speaker_promts]\n",
    "            data_loader = DataLoader(all_promtings_texts, \n",
    "                                batch_size=batch_size, \n",
    "                                shuffle=False)\n",
    "            output_sp_desc = []\n",
    "            with torch.no_grad():\n",
    "                for i, speaker_promts_in_batch in enumerate(data_loader):\n",
    "                    # batch decoded by llm \n",
    "                    inputs = tokenizer(speaker_promts_in_batch, return_tensors=\"pt\", padding=False)\n",
    "                    input_ids = inputs[\"input_ids\"].to(\"cuda\")\n",
    "                    with torch.no_grad():\n",
    "                        outputs = model.generate(input_ids, max_new_tokens=300)\n",
    "                    output_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "                    \n",
    "                    for j, e in enumerate(output_text):\n",
    "                        output_sp_desc.append(e.replace(all_promtings_texts[j], \"\"))\n",
    "                        \n",
    "                    if print_one_time: \n",
    "                        print(output_text)\n",
    "                        print(output_sp_desc)\n",
    "                        print_one_time = False\n",
    "            \n",
    "                for i, out in enumerate(output_sp_desc):\n",
    "                    speaker_promts[i]['sp_desc'] = out  \n",
    "            break\n",
    "                    \n",
    "        except Exception as e:\n",
    "            traceback.print_exc()\n",
    "            print(e)\n",
    "            if batch_size == 1:\n",
    "                print([\"Errr \"]*10)\n",
    "                \n",
    "for type_data in ['valid', 'test', 'train']:\n",
    "    data_name_pattern= f'{dataset_name}.{type_data}'\n",
    "    path_processed_data = f'{data_folder}/llm_vectors/{data_name_pattern}_{prompt_type}_{model_name.split(\"/\")[-1]}.json'\n",
    "    \n",
    "    processed_data = {}\n",
    "    if os.path.exists(path_processed_data):\n",
    "        processed_data = json.load(open(path_processed_data, 'rt'))\n",
    "        print(f'- load processed [old] {len(processed_data)} conversations in data-type ={type_data}')\n",
    "        \n",
    "    all_data = {}\n",
    "    for len_promting, speaker_promts in gr_by_len.items():\n",
    "        for description in speaker_promts:\n",
    "            if type_data != description['type_data']:\n",
    "                continue\n",
    "            \n",
    "            if description['conv_id'] not in all_data:\n",
    "                all_data[description['conv_id']] = {\n",
    "                    'all_speaker_names': description['all_speaker_names'],\n",
    "                    'vocab_sp2desc':  {}\n",
    "                }\n",
    "            all_data[description['conv_id']]['vocab_sp2desc'][description['speaker_name']] = description['sp_desc']\n",
    "    \n",
    "    print(f'- sucessful processed [new] {len(all_data)} conversations in data-type ={type_data}')\n",
    "    # json.dump(all_data, open(f'{path_data}_new.json', 'wt'), indent=2)\n",
    "\n",
    "    all_data_new = {}\n",
    "    for k, v in all_data.items():\n",
    "        all_data_new[k] = []\n",
    "        for sp_name in v['all_speaker_names']:\n",
    "            all_data_new[k].append(v['vocab_sp2desc'][sp_name])\n",
    "            \n",
    "    print(f'- update processed [new] {len(all_data_new)} + [old] {len(processed_data)} conversations in data-type ={type_data}')\n",
    "    all_data_new.update(processed_data)\n",
    "    json.dump(all_data_new, open(f'{path_processed_data}', 'wt'), indent=2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
